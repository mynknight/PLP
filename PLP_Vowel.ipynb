{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acf334f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved to vowel_formant_features.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def extract_vowel_from_filename(filename):\n",
    "    match = re.search(r'[a-zA-Z]', filename)\n",
    "    if match:\n",
    "        return match.group().lower()\n",
    "    return None\n",
    "\n",
    "def process_folder(input_folder, output_csv, sampling_rate=16000):\n",
    "    data = []\n",
    "    \n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            samples = read_samples_from_txt(file_path)\n",
    "            \n",
    "            lpcas = extract_plp_features(samples, sampling_rate=sampling_rate)\n",
    "            if lpcas is None:\n",
    "                continue\n",
    "\n",
    "            w, h = compute_lpc_filter_and_response(lpcas)\n",
    "\n",
    "            formant_1_w, formant_2_w = find_formants_across_frames(w, h)\n",
    "\n",
    "            # Convert to Hertz\n",
    "            formant_1_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_1_w]\n",
    "            formant_2_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_2_w]\n",
    "\n",
    "            vowel = extract_vowel_from_filename(filename)\n",
    "            if vowel is None:\n",
    "                print(f\"Could not extract vowel from {filename}\")\n",
    "                continue\n",
    "\n",
    "            # Prepare data for CSV\n",
    "            for f1, f2 in zip(formant_1_Hz, formant_2_Hz):\n",
    "                if f1 is not None and f2 is not None:\n",
    "                    data.append([f1, f2, vowel])\n",
    "    \n",
    "    # Save data to CSV\n",
    "    df = pd.DataFrame(data, columns=['Formant_1_Hz', 'Formant_2_Hz', 'Vowel'])\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Features saved to {output_csv}\")\n",
    "\n",
    "# Example usage\n",
    "input_folder = r\"Vowel_recordings\"\n",
    "output_csv = r\"vowel_formant_features.csv\"\n",
    "process_folder(input_folder, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21081d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score: 0.4432\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(output_csv)\n",
    "\n",
    "# Encode vowel labels\n",
    "le = LabelEncoder()\n",
    "df['Vowel_Encoded'] = le.fit_transform(df['Vowel'])\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X = df[['Formant_1_Hz', 'Formant_2_Hz']]\n",
    "y = df['Vowel_Encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest Regressor\n",
    "rfr = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "score = rfr.score(X_test, y_test)\n",
    "print(f\"Model score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c89cccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved to vowel_formant_features.csv\n",
      "Train accuracy: 0.95\n",
      "Test accuracy: 0.74\n",
      "Cross-validation accuracy: 0.72 (+/- 0.03)\n",
      "Predicted vowels saved to predicted_vowels.csv\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from scipy.signal import freqz\n",
    "import peakutils\n",
    "from sidekit.frontend.features import plp\n",
    "\n",
    "def read_samples_from_txt(file_path):\n",
    "    samples = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            samples.extend([float(value) for value in line.strip().split()])\n",
    "    return np.array(samples)\n",
    "\n",
    "def extract_plp_features(samples, sampling_rate=16000, rasta=False, plp_order=10):\n",
    "    try:\n",
    "        lpcas = plp(samples, fs=sampling_rate, rasta=rasta, plp_order=plp_order)\n",
    "        return lpcas\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting PLP features: {e}\")\n",
    "        return None\n",
    "\n",
    "def compute_lpc_filter_and_response(lpc_coeffs):\n",
    "    if lpc_coeffs is None:\n",
    "        raise ValueError(\"LPC coefficients are not provided.\")\n",
    "    \n",
    "    if isinstance(lpc_coeffs, (list, np.ndarray)):\n",
    "        lpc_coeffs = np.array(lpc_coeffs)\n",
    "        if lpc_coeffs.ndim != 2:\n",
    "            raise ValueError(\"LPC coefficients must be a 2D array (frames x order).\")\n",
    "    \n",
    "    num_frames, num_order = lpc_coeffs.shape\n",
    "    all_w = []\n",
    "    all_h = []\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        lpc_filter = np.concatenate(([1], -lpc_coeffs[i]))\n",
    "        w, h = freqz(lpc_filter)\n",
    "        all_w.append(w)\n",
    "        all_h.append(h)\n",
    "    \n",
    "    all_w = np.array(all_w)\n",
    "    all_h = np.array(all_h)\n",
    "    \n",
    "    return all_w, all_h\n",
    "\n",
    "def find_formants_across_frames(w, h):\n",
    "    formant_1_w = []\n",
    "    formant_2_w = []\n",
    "    formant_3_w = []\n",
    "    \n",
    "    for i in range(w.shape[0]):\n",
    "        h_db = 20 * np.log10(np.abs(h[i]))\n",
    "        peak_indices = peakutils.indexes(h_db)\n",
    "\n",
    "        if peak_indices.size > 2:\n",
    "            formant_1_w.append(w[i][peak_indices[0]])\n",
    "            formant_2_w.append(w[i][peak_indices[1]])\n",
    "            formant_3_w.append(w[i][peak_indices[2]])\n",
    "        else:\n",
    "            formant_1_w.append(None)\n",
    "            formant_2_w.append(None)\n",
    "            formant_3_w.append(None)\n",
    "    \n",
    "    return formant_1_w, formant_2_w, formant_3_w\n",
    "\n",
    "def extract_vowel_from_filename(filename):\n",
    "    match = re.search(r'[a-zA-Z]', filename)\n",
    "    if match:\n",
    "        return match.group().lower()\n",
    "    return None\n",
    "\n",
    "def process_folder(input_folder, output_csv, sampling_rate=16000):\n",
    "    data = []\n",
    "    \n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            samples = read_samples_from_txt(file_path)\n",
    "            \n",
    "            lpcas = extract_plp_features(samples, sampling_rate=sampling_rate)\n",
    "            if lpcas is None:\n",
    "                continue\n",
    "\n",
    "            w, h = compute_lpc_filter_and_response(lpcas)\n",
    "\n",
    "            formant_1_w, formant_2_w, formant_3_w = find_formants_across_frames(w, h)\n",
    "\n",
    "            formant_1_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_1_w]\n",
    "            formant_2_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_2_w]\n",
    "            formant_3_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_3_w]\n",
    "\n",
    "            vowel = extract_vowel_from_filename(filename)\n",
    "            if vowel is None:\n",
    "                print(f\"Could not extract vowel from {filename}\")\n",
    "                continue\n",
    "\n",
    "            for f1, f2, f3 in zip(formant_1_Hz, formant_2_Hz, formant_3_Hz):\n",
    "                if f1 is not None and f2 is not None and f3 is not None:\n",
    "                    data.append([f1, f2, f3, vowel])\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=['Formant_1_Hz', 'Formant_2_Hz', 'Formant_3_Hz', 'Vowel'])\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Features saved to {output_csv}\")\n",
    "\n",
    "def train_random_forest(output_csv):\n",
    "    df = pd.read_csv(output_csv)\n",
    "    le = LabelEncoder()\n",
    "    df['Vowel_Encoded'] = le.fit_transform(df['Vowel'])\n",
    "    X = df[['Formant_1_Hz', 'Formant_2_Hz', 'Formant_3_Hz']]\n",
    "    y = df['Vowel_Encoded']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Using the given hyperparameters directly\n",
    "    best_params = {\n",
    "        'max_depth': 20,\n",
    "        'max_features': 'auto',\n",
    "        'min_samples_leaf': 1,\n",
    "        'min_samples_split': 5,\n",
    "        'n_estimators': 100\n",
    "    }\n",
    "\n",
    "    rfc = RandomForestClassifier(random_state=42, **best_params)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate model performance\n",
    "    train_accuracy = rfc.score(X_train, y_train)\n",
    "    test_accuracy = rfc.score(X_test, y_test)\n",
    "    print(f\"Train accuracy: {train_accuracy:.2f}\")\n",
    "    print(f\"Test accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(rfc, X, y, cv=5)\n",
    "    print(f\"Cross-validation accuracy: {cv_scores.mean():.2f} (+/- {cv_scores.std():.2f})\")\n",
    "\n",
    "    return rfc, le\n",
    "\n",
    "def classify_files(input_folder, model, le, sampling_rate=16000, output_csv=\"predicted_vowels.csv\"):\n",
    "    results = []\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            samples = read_samples_from_txt(file_path)\n",
    "            \n",
    "            lpcas = extract_plp_features(samples, sampling_rate=sampling_rate)\n",
    "            if lpcas is None:\n",
    "                continue\n",
    "\n",
    "            w, h = compute_lpc_filter_and_response(lpcas)\n",
    "\n",
    "            formant_1_w, formant_2_w, formant_3_w = find_formants_across_frames(w, h)\n",
    "\n",
    "            formant_1_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_1_w]\n",
    "            formant_2_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_2_w]\n",
    "            formant_3_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_3_w]\n",
    "\n",
    "            frame_features = []\n",
    "            for f1, f2, f3 in zip(formant_1_Hz, formant_2_Hz, formant_3_Hz):\n",
    "                if f1 is not None and f2 is not None and f3 is not None:\n",
    "                    frame_features.append([f1, f2, f3])\n",
    "\n",
    "            if not frame_features:\n",
    "                continue\n",
    "\n",
    "            frame_features_df = pd.DataFrame(frame_features, columns=['Formant_1_Hz', 'Formant_2_Hz', 'Formant_3_Hz'])\n",
    "            predicted_vowels = model.predict(frame_features_df)\n",
    "            predicted_vowels = le.inverse_transform(predicted_vowels.astype(int))\n",
    "\n",
    "            predicted_vowel, count = np.unique(predicted_vowels, return_counts=True)\n",
    "            classified_vowel = predicted_vowel[np.argmax(count)]\n",
    "\n",
    "            actual_vowel = extract_vowel_from_filename(filename)\n",
    "            results.append((filename, actual_vowel, classified_vowel))\n",
    "\n",
    "    df_results = pd.DataFrame(results, columns=[\"Filename\", \"Actual Vowel\", \"Predicted Vowel\"])\n",
    "    df_results.to_csv(output_csv, index=False)\n",
    "    print(f\"Predicted vowels saved to {output_csv}\")\n",
    "\n",
    "    correct_predictions = df_results[df_results['Actual Vowel'] == df_results['Predicted Vowel']].shape[0]\n",
    "    total_predictions = df_results.shape[0]\n",
    "    accuracy = (correct_predictions / total_predictions) * 100\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Example usage\n",
    "input_folder = r\"Vowel_recordings\"\n",
    "output_csv = r\"vowel_formant_features.csv\"\n",
    "process_folder(input_folder, output_csv)\n",
    "\n",
    "rfc, le = train_random_forest(output_csv)\n",
    "classify_files(input_folder, rfc, le)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5fbe25a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved to vowel_formant_features.csv\n",
      "Train accuracy: 0.71\n",
      "Test accuracy: 0.70\n",
      "Cross-validation accuracy: 0.69 (+/- 0.01)\n",
      "Predicted vowels saved to predicted_vowels.csv\n",
      "Accuracy: 99.33%\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from scipy.signal import freqz\n",
    "import peakutils\n",
    "from sidekit.frontend.features import plp\n",
    "import pickle\n",
    "\n",
    "def read_samples_from_txt(file_path):\n",
    "    samples = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            samples.extend([float(value) for value in line.strip().split()])\n",
    "    return np.array(samples)\n",
    "\n",
    "def extract_plp_features(samples, sampling_rate=16000, rasta=False, plp_order=10):\n",
    "    try:\n",
    "        lpcas = plp(samples, fs=sampling_rate, rasta=rasta, plp_order=plp_order)\n",
    "        return lpcas\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting PLP features: {e}\")\n",
    "        return None\n",
    "\n",
    "def compute_lpc_filter_and_response(lpc_coeffs):\n",
    "    if lpc_coeffs is None:\n",
    "        raise ValueError(\"LPC coefficients are not provided.\")\n",
    "    \n",
    "    if isinstance(lpc_coeffs, (list, np.ndarray)):\n",
    "        lpc_coeffs = np.array(lpc_coeffs)\n",
    "        if lpc_coeffs.ndim != 2:\n",
    "            raise ValueError(\"LPC coefficients must be a 2D array (frames x order).\")\n",
    "    \n",
    "    num_frames, num_order = lpc_coeffs.shape\n",
    "    all_w = []\n",
    "    all_h = []\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        lpc_filter = np.concatenate(([1], -lpc_coeffs[i]))\n",
    "        w, h = freqz(lpc_filter)\n",
    "        all_w.append(w)\n",
    "        all_h.append(h)\n",
    "    \n",
    "    all_w = np.array(all_w)\n",
    "    all_h = np.array(all_h)\n",
    "    \n",
    "    return all_w, all_h\n",
    "\n",
    "def find_formants_across_frames(w, h):\n",
    "    formant_1_w = []\n",
    "    formant_2_w = []\n",
    "    formant_3_w = []\n",
    "    \n",
    "    for i in range(w.shape[0]):\n",
    "        h_db = 20 * np.log10(np.abs(h[i]))\n",
    "        peak_indices = peakutils.indexes(h_db)\n",
    "\n",
    "        if peak_indices.size > 2:\n",
    "            formant_1_w.append(w[i][peak_indices[0]])\n",
    "            formant_2_w.append(w[i][peak_indices[1]])\n",
    "            formant_3_w.append(w[i][peak_indices[2]])\n",
    "        else:\n",
    "            formant_1_w.append(None)\n",
    "            formant_2_w.append(None)\n",
    "            formant_3_w.append(None)\n",
    "    \n",
    "    return formant_1_w, formant_2_w, formant_3_w\n",
    "\n",
    "def extract_vowel_from_filename(filename):\n",
    "    match = re.search(r'[a-zA-Z]', filename)\n",
    "    if match:\n",
    "        return match.group().lower()\n",
    "    return None\n",
    "\n",
    "def process_folder(input_folder, output_csv, sampling_rate=16000):\n",
    "    data = []\n",
    "    \n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            samples = read_samples_from_txt(file_path)\n",
    "            \n",
    "            lpcas = extract_plp_features(samples, sampling_rate=sampling_rate)\n",
    "            if lpcas is None:\n",
    "                continue\n",
    "\n",
    "            w, h = compute_lpc_filter_and_response(lpcas)\n",
    "\n",
    "            formant_1_w, formant_2_w, formant_3_w = find_formants_across_frames(w, h)\n",
    "\n",
    "            formant_1_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_1_w]\n",
    "            formant_2_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_2_w]\n",
    "            formant_3_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_3_w]\n",
    "\n",
    "            vowel = extract_vowel_from_filename(filename)\n",
    "            if vowel is None:\n",
    "                print(f\"Could not extract vowel from {filename}\")\n",
    "                continue\n",
    "\n",
    "            for f1, f2, f3 in zip(formant_1_Hz, formant_2_Hz, formant_3_Hz):\n",
    "                if f1 is not None and f2 is not None and f3 is not None:\n",
    "                    data.append([f1, f2, f3, vowel])\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=['Formant_1_Hz', 'Formant_2_Hz', 'Formant_3_Hz', 'Vowel'])\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Features saved to {output_csv}\")\n",
    "\n",
    "def train_random_forest(output_csv):\n",
    "    df = pd.read_csv(output_csv)\n",
    "    le = LabelEncoder()\n",
    "    df['Vowel_Encoded'] = le.fit_transform(df['Vowel'])\n",
    "    X = df[['Formant_1_Hz', 'Formant_2_Hz', 'Formant_3_Hz']]\n",
    "    y = df['Vowel_Encoded']\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Using the given hyperparameters directly\n",
    "    best_params = {\n",
    "        'max_depth': 5,\n",
    "        'max_features': 'auto',\n",
    "        'min_samples_leaf': 1,\n",
    "        'min_samples_split': 5,\n",
    "        'n_estimators': 100\n",
    "    }\n",
    "\n",
    "    rfc = RandomForestClassifier(random_state=42, **best_params)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate model performance\n",
    "    train_accuracy = rfc.score(X_train, y_train)\n",
    "    test_accuracy = rfc.score(X_test, y_test)\n",
    "    print(f\"Train accuracy: {train_accuracy:.2f}\")\n",
    "    print(f\"Test accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(rfc, X, y, cv=5)\n",
    "    print(f\"Cross-validation accuracy: {cv_scores.mean():.2f} (+/- {cv_scores.std():.2f})\")\n",
    "\n",
    "    # Save the model and label encoder\n",
    "    with open('vowel_classifier_model.pkl', 'wb') as f:\n",
    "        pickle.dump((rfc, le), f)\n",
    "\n",
    "    return rfc, le\n",
    "\n",
    "def classify_files(input_folder, model, le, sampling_rate=16000, output_csv=\"predicted_vowels.csv\"):\n",
    "    results = []\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(input_folder, filename)\n",
    "            samples = read_samples_from_txt(file_path)\n",
    "            \n",
    "            lpcas = extract_plp_features(samples, sampling_rate=sampling_rate)\n",
    "            if lpcas is None:\n",
    "                continue\n",
    "\n",
    "            w, h = compute_lpc_filter_and_response(lpcas)\n",
    "\n",
    "            formant_1_w, formant_2_w, formant_3_w = find_formants_across_frames(w, h)\n",
    "\n",
    "            formant_1_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_1_w]\n",
    "            formant_2_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_2_w]\n",
    "            formant_3_Hz = [(x * sampling_rate) / (2 * math.pi) if x is not None else None for x in formant_3_w]\n",
    "\n",
    "            frame_features = []\n",
    "            for f1, f2, f3 in zip(formant_1_Hz, formant_2_Hz, formant_3_Hz):\n",
    "                if f1 is not None and f2 is not None and f3 is not None:\n",
    "                    frame_features.append([f1, f2, f3])\n",
    "\n",
    "            if not frame_features:\n",
    "                continue\n",
    "\n",
    "            frame_features_df = pd.DataFrame(frame_features, columns=['Formant_1_Hz', 'Formant_2_Hz', 'Formant_3_Hz'])\n",
    "            predicted_vowels = model.predict(frame_features_df)\n",
    "            predicted_vowels = le.inverse_transform(predicted_vowels.astype(int))\n",
    "\n",
    "            predicted_vowel, count = np.unique(predicted_vowels, return_counts=True)\n",
    "            classified_vowel = predicted_vowel[np.argmax(count)]\n",
    "\n",
    "            actual_vowel = extract_vowel_from_filename(filename)\n",
    "            results.append((filename, actual_vowel, classified_vowel))\n",
    "\n",
    "    df_results = pd.DataFrame(results, columns=[\"Filename\", \"Actual Vowel\", \"Predicted Vowel\"])\n",
    "    df_results.to_csv(output_csv, index=False)\n",
    "    print(f\"Predicted vowels saved to {output_csv}\")\n",
    "\n",
    "    correct_predictions = df_results[df_results['Actual Vowel'] == df_results['Predicted Vowel']].shape[0]\n",
    "    total_predictions = df_results.shape[0]\n",
    "    accuracy = (correct_predictions / total_predictions) * 100\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Example usage\n",
    "input_folder = r\"Vowel_recordings\"\n",
    "output_csv = r\"vowel_formant_features.csv\"\n",
    "process_folder(input_folder, output_csv)\n",
    "\n",
    "rfc, le = train_random_forest(output_csv)\n",
    "classify_files(input_folder, rfc, le)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0449385a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msounddevice\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msignal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m freqz\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\__init__.py:59\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# dtype\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     ArrowDtype,\n\u001b[0;32m     62\u001b[0m     Int8Dtype,\n\u001b[0;32m     63\u001b[0m     Int16Dtype,\n\u001b[0;32m     64\u001b[0m     Int32Dtype,\n\u001b[0;32m     65\u001b[0m     Int64Dtype,\n\u001b[0;32m     66\u001b[0m     UInt8Dtype,\n\u001b[0;32m     67\u001b[0m     UInt16Dtype,\n\u001b[0;32m     68\u001b[0m     UInt32Dtype,\n\u001b[0;32m     69\u001b[0m     UInt64Dtype,\n\u001b[0;32m     70\u001b[0m     Float32Dtype,\n\u001b[0;32m     71\u001b[0m     Float64Dtype,\n\u001b[0;32m     72\u001b[0m     CategoricalDtype,\n\u001b[0;32m     73\u001b[0m     PeriodDtype,\n\u001b[0;32m     74\u001b[0m     IntervalDtype,\n\u001b[0;32m     75\u001b[0m     DatetimeTZDtype,\n\u001b[0;32m     76\u001b[0m     StringDtype,\n\u001b[0;32m     77\u001b[0m     BooleanDtype,\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# missing\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     NA,\n\u001b[0;32m     80\u001b[0m     isna,\n\u001b[0;32m     81\u001b[0m     isnull,\n\u001b[0;32m     82\u001b[0m     notna,\n\u001b[0;32m     83\u001b[0m     notnull,\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# indexes\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     Index,\n\u001b[0;32m     86\u001b[0m     CategoricalIndex,\n\u001b[0;32m     87\u001b[0m     RangeIndex,\n\u001b[0;32m     88\u001b[0m     MultiIndex,\n\u001b[0;32m     89\u001b[0m     IntervalIndex,\n\u001b[0;32m     90\u001b[0m     TimedeltaIndex,\n\u001b[0;32m     91\u001b[0m     DatetimeIndex,\n\u001b[0;32m     92\u001b[0m     PeriodIndex,\n\u001b[0;32m     93\u001b[0m     IndexSlice,\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;66;03m# tseries\u001b[39;00m\n\u001b[0;32m     95\u001b[0m     NaT,\n\u001b[0;32m     96\u001b[0m     Period,\n\u001b[0;32m     97\u001b[0m     period_range,\n\u001b[0;32m     98\u001b[0m     Timedelta,\n\u001b[0;32m     99\u001b[0m     timedelta_range,\n\u001b[0;32m    100\u001b[0m     Timestamp,\n\u001b[0;32m    101\u001b[0m     date_range,\n\u001b[0;32m    102\u001b[0m     bdate_range,\n\u001b[0;32m    103\u001b[0m     Interval,\n\u001b[0;32m    104\u001b[0m     interval_range,\n\u001b[0;32m    105\u001b[0m     DateOffset,\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;66;03m# conversion\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     to_numeric,\n\u001b[0;32m    108\u001b[0m     to_datetime,\n\u001b[0;32m    109\u001b[0m     to_timedelta,\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;66;03m# misc\u001b[39;00m\n\u001b[0;32m    111\u001b[0m     Flags,\n\u001b[0;32m    112\u001b[0m     Grouper,\n\u001b[0;32m    113\u001b[0m     factorize,\n\u001b[0;32m    114\u001b[0m     unique,\n\u001b[0;32m    115\u001b[0m     value_counts,\n\u001b[0;32m    116\u001b[0m     NamedAgg,\n\u001b[0;32m    117\u001b[0m     array,\n\u001b[0;32m    118\u001b[0m     Categorical,\n\u001b[0;32m    119\u001b[0m     set_eng_float_format,\n\u001b[0;32m    120\u001b[0m     Series,\n\u001b[0;32m    121\u001b[0m     DataFrame,\n\u001b[0;32m    122\u001b[0m )\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseDtype\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtseries\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_freq\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     NaT,\n\u001b[0;32m      3\u001b[0m     Period,\n\u001b[0;32m      4\u001b[0m     Timedelta,\n\u001b[0;32m      5\u001b[0m     Timestamp,\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmissing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NA\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     ArrowDtype,\n\u001b[0;32m     11\u001b[0m     CategoricalDtype,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     PeriodDtype,\n\u001b[0;32m     15\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\_libs\\__init__.py:18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_parser\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas_datetime\u001b[39;00m  \u001b[38;5;66;03m# noqa: F401,E501 # isort: skip # type: ignore[reportUnusedImport]\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     NaT,\n\u001b[0;32m     21\u001b[0m     NaTType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m     iNaT,\n\u001b[0;32m     27\u001b[0m )\n",
      "File \u001b[1;32minterval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.signal import freqz\n",
    "import peakutils\n",
    "from sidekit.frontend.features import plp\n",
    "\n",
    "\n",
    "\n",
    "# Load the model and label encoder\n",
    "with open('vowel_classifier_model.pkl', 'rb') as f:\n",
    "    rfc, le = pickle.load(f)\n",
    "\n",
    "def record_audio(duration, fs):\n",
    "    print(\"Recording...\")\n",
    "    audio = sd.rec(int(duration * fs), samplerate=fs, channels=1, dtype='float64')\n",
    "    sd.wait()\n",
    "    print(\"Recording complete\")\n",
    "    audio = audio.flatten()\n",
    "    return audio\n",
    "\n",
    "def trim_audio(audio, fs, threshold):\n",
    "    max_amplitude = np.max(np.abs(audio))\n",
    "    amplitude_threshold = threshold * max_amplitude\n",
    "    audio[np.abs(audio) < amplitude_threshold] = 0\n",
    "    start_idx = np.argmax(audio > amplitude_threshold)\n",
    "    end_idx = len(audio) - np.argmax(audio[::-1] > amplitude_threshold)\n",
    "    return audio[start_idx:end_idx]\n",
    "\n",
    "def predict_vowel(audio, fs, model, le):\n",
    "    lpcas = extract_plp_features(audio, sampling_rate=fs)\n",
    "    if lpcas is None:\n",
    "        return None\n",
    "\n",
    "    w, h = compute_lpc_filter_and_response(lpcas)\n",
    "    formant_1_w, formant_2_w, formant_3_w = find_formants_across_frames(w, h)\n",
    "\n",
    "    formant_1_Hz = [(x * fs) / (2 * np.pi) if x is not None else None for x in formant_1_w]\n",
    "    formant_2_Hz = [(x * fs) / (2 * np.pi) if x is not None else None for x in formant_2_w]\n",
    "    formant_3_Hz = [(x * fs) / (2 * np.pi) if x is not None else None for x in formant_3_w]\n",
    "\n",
    "    frame_features = []\n",
    "    for f1, f2, f3 in zip(formant_1_Hz, formant_2_Hz, formant_3_Hz):\n",
    "        if f1 is not None and f2 is not None and f3 is not None:\n",
    "            frame_features.append([f1, f2, f3])\n",
    "\n",
    "    if not frame_features:\n",
    "        return None\n",
    "\n",
    "    frame_features_df = pd.DataFrame(frame_features, columns=['Formant_1_Hz', 'Formant_2_Hz', 'Formant_3_Hz'])\n",
    "    predicted_vowels = model.predict(frame_features_df)\n",
    "    predicted_vowels = le.inverse_transform(predicted_vowels.astype(int))\n",
    "\n",
    "    predicted_vowel, count = np.unique(predicted_vowels, return_counts=True)\n",
    "    return predicted_vowel[np.argmax(count)]\n",
    "\n",
    "# Parameters\n",
    "duration = 5  # seconds\n",
    "fs = 16000  # sampling rate\n",
    "threshold = 0.01\n",
    "\n",
    "# Record and trim audio\n",
    "audio = record_audio(duration, fs)\n",
    "trimmed_audio = trim_audio(audio, fs, threshold)\n",
    "\n",
    "# Predict vowel\n",
    "\n",
    "predicted_vowel = predict_vowel(trimmed_audio, fs, rfc, le)\n",
    "print(f\"Predicted Vowel: {predicted_vowel}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e9be611",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall pandas\n",
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de99a623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
